distMats<-makeDists(cbind(ns.data.re$x.pos, ns.data.re$y.pos), na.omit(knotgrid.ns))
# set initial model without the spatial term
# (so all other non-spline terms)
initialModel<- glm(response ~ as.factor(floodebb) + as.factor(impact) + offset(log(area)),
family='quasipoisson', data=ns.data.re)
# make parameter set for running salsa2d
# I have chosen a gap parameter of 1000 (in metres) to speed up the process.
# Note that this means there cannot be two knots within 1000m of each other.
salsa2dlist<-list(fitnessMeasure = 'QICb', knotgrid = na.omit(knotgrid.ns),
startKnots=6, minKnots=4, maxKnots=20, gap=1000,
interactionTerm="as.factor(impact)")
salsa2dOutput_k6<-runSALSA2D(initialModel, salsa2dlist, d2k=distMats$dataDist,
k2k=distMats$knotDist)
debugonce(runSALSA2D)
data(ns.data.re)
# load prediction data
data(ns.predict.data.re)
# load knot grid data
data(knotgrid.ns)
#set some input info for SALSA
ns.data.re$response<- ns.data.re$birds
# make distance matrices for datatoknots and knottoknots
distMats<-makeDists(cbind(ns.data.re$x.pos, ns.data.re$y.pos), na.omit(knotgrid.ns))
# set initial model without the spatial term
# (so all other non-spline terms)
initialModel<- glm(response ~ as.factor(floodebb) + as.factor(impact) + offset(log(area)),
family='quasipoisson', data=ns.data.re)
# make parameter set for running salsa2d
# I have chosen a gap parameter of 1000 (in metres) to speed up the process.
# Note that this means there cannot be two knots within 1000m of each other.
salsa2dlist<-list(fitnessMeasure = 'QICb', knotgrid = na.omit(knotgrid.ns),
startKnots=6, minKnots=4, maxKnots=20, gap=1000,
interactionTerm="as.factor(impact)")
salsa2dOutput_k6<-runSALSA2D(initialModel, salsa2dlist, d2k=distMats$dataDist,
k2k=distMats$knotDist)
output$models
memory.limit()
devtools::install_github("lindesaysh/MRSea", ref="master")
require(MRSea)
install.packages("xfun")
citation("MRSea")
citation("MRSeaPower")
setwd('C:/Documents and Settings/lass/University of St Andrews/MLM_LSHjointwork - Documents/research/USA_DOEGrant/')
# dat<-read.csv('NEAQ_segments_v2.csv')
#
# head(dat)
# plot(dat$Longitude, dat$Latitude)
#
require(fields)
# quilt.plot(dat$Longitude, dat$Latitude, dat$numanimls_RIWH)
# quilt.plot(dat$Longitude, dat$Latitude, dat$numanimls_HUWH)
# quilt.plot(dat$Longitude, dat$Latitude, dat$numanimls_SEWH)
# quilt.plot(dat$Longitude, dat$Latitude, dat$numanimls_FIWH)
# quilt.plot(dat$Longitude, dat$Latitude, dat$numanimls_MIWH)
#
# table(dat$numanimls_RIWH)
# table(dat$numanimls_HUWH)
# table(dat$numanimls_SEWH)
# table(dat$numanimls_FIWH)
# table(dat$numanimls_MIWH)
#
require(dplyr)
# dat<-mutate(dat, allanim = numanimls_RIWH + numanimls_HUWH + numanimls_SEWH + numanimls_FIWH + numanimls_MIWH)
#
# quilt.plot(dat$Longitude, dat$Latitude, dat$allanim)
#
#
# # dat$datetime <-
# #   as.POSIXct(dat$Date, format = "%m-%d-%Y")
# # dat$year <- year(dat$datetime)
# # dat$month <- month(dat$datetime)
#
# dat<-data.frame(dat, data.frame(matrix(unlist(strsplit(dat$Date, "/")), ncol=3, byrow=TRUE)))
# names(dat)[19:21] <- c('month', 'day', 'year')
#
# dat$month <- as.numeric(dat$month)
# dat$day <- as.numeric(dat$day)
# dat$year <- as.numeric(dat$year)
#
# dat$season <- ifelse(dat$month >=5 & dat$month<=10, "Summer", "Winter")
# table(dat$season, dat$month)
#
require(sp)
# cd<-SpatialPointsDataFrame(coords=cbind(dat$Longitude, dat$Latitude), data=dat)
# proj4string(cd) <- CRS("+proj=longlat")
# cd<-spTransform(cd, CRS("+proj=utm +zone=19N"))
# cd$x.pos<-cd@coords[,1]/1000
# cd$y.pos<-cd@coords[,2]/1000
#
# dat<-cd@data
#
require(rgdal)
require(raster)
require(ggplot2)
# study <- readOGR(dsn = 'Power Analysis Files/General survey area', layer = "GeneralSurveyAreaALL", verbose = FALSE)
# study <- spTransform(study, CRS("+proj=utm +zone=19N"))
# study_fort <- fortify(study)
# study_fort <- mutate(study_fort, x = long / 1000, y = lat / 1000)
#
# lease <- readOGR(dsn = 'Power Analysis Files/Lease_Area_Polys_outline', layer = "BOEM_Lease_Areas_2_13_2019_Outline", verbose = FALSE)
# lease <- spTransform(lease, CRS("+proj=utm +zone=19N"))
# lease_fort <- fortify(lease)
# lease_fort <- mutate(lease_fort, x = long / 1000, y = lat / 1000)
# lease_fort<-filter(lease_fort, x > 300)
#
# leasenames<-data.frame(Lease = c('DWW', 'DWW', 'Deepwater_NE', 'Deepwater_NE', 'Sunrise_Bay', 'Sunrise_Bay','Vineyard_01', 'Equinor', 'Mayflower', 'Vineyard_22'), group = as.factor(c(2.1, 2.2, 3.1, 3.2, 6.1, 6.2, 7.1, 14.1, 15.1, 16.1)))
#
# lease_fort<-left_join(lease_fort, leasenames)
#
# leasebuf<-data.frame(buffer(SpatialPolygons(list(Polygons(list(Polygon(filter(lease_fort, group == 6.1) %>% dplyr::select(x, y))),ID=1))), width=5)@polygons[[1]]@Polygons[[1]]@coords)
#
# #dat<-filter(dat, month %in% c(11:12, 1:4))
#
# dat_summer<-filter(dat, season == 'Summer')
#
#
# ggplot() + geom_path(data=study_fort, aes(x=x, y=y, group=group),  colour='black')  +
#   geom_point(data=dat_summer, aes(x=x.pos, y=y.pos), colour='darkgrey', alpha=0.5) +
#   geom_path(data=lease_fort, aes(x=x, y=y, group=group, colour=Lease), size=1) +
#   theme_bw() + xlab('Easting') + ylab('Northing') + ggtitle('Study Area') + coord_equal()
#
#
# # require(mgcv)
# # test<-gam(num_animls_right ~ s(Longitude, Latitude), family = 'quasipoisson', data=dat)
# # quilt.plot(dat$Longitude, dat$Latitude, fitted(test))
# # test<-gam(num_sights_right ~ s(Longitude, Latitude), family = 'quasibinomial', data=dat)
# # quilt.plot(dat$Longitude, dat$Latitude, fitted(test))
#
require(MRSea)
#
# kg<-getKnotgrid(coordData = dat_summer[,c('x.pos', 'y.pos')])
# dists<-makeDists(datacoords = dat_summer[,c('x.pos', 'y.pos')], knotcoords = kg, knotmat = TRUE)
# d2k = dists$dataDist
# k2k = dists$knotDist
# #dat$response <- dat$num_animls_right
# dat_summer$response <- dat_summer$allanim
#
# initialModel <- glm(response ~ 1 + offset(log(Effort)), data=dat_summer, family='quasipoisson')
#
# #dat$response <- dat$allanim
# #initialModel <- glm(response ~ 1, data=dat, family='quasipoisson')
#
#
#  #dat$response <- dat$num_sights_right
#  #initialModel <- glm(response ~ 1, data=dat, family='binomial')
#
#
# salsa2dlist <- list(fitnessMeasure = 'QBIC',
#                     knotgrid = kg,
#                     startKnots = 10,
#                     minKnots = 2,
#                     maxKnots = 25,
#                     cv.opts=list(cv.gamMRSea.seed=357, K=10)
# )
#
# salsa2doutput<-runSALSA2D(model = initialModel, salsa2dlist = salsa2dlist, d2k= d2k, k2k = k2k,
#                           basis='gaussian', suppress.printout = FALSE)
#
# dat_summer$block <- paste0(dat_summer$LEGNO2, dat_summer$Date)
# bestmod<-make.gamMRSea(salsa2doutput$bestModel, panelid = dat_summer$block)
#
# summary(bestmod)
#
# par(mfrow=c(1,2))
# quilt.plot(dat_summer$x.pos, dat_summer$y.pos, fitted(salsa2doutput$bestModel), asp=1)
# quilt.plot(dat_summer$x.pos, dat_summer$y.pos, dat_summer$response - fitted(salsa2doutput$bestModel), asp=1)
#
# quilt.plot(dat_summer$x.pos, dat_summer$y.pos, dat_summer$response, asp=1, nrow=10, ncol=10)
#
# # eventsite1 <- data.frame(x.pos = c(343.7165, 350.3463, 389.1306, 367.2523, 343.7165),
# #                         y.pos = c(4522.872, 4515.911, 4549.723, 4555.026,4522.872))
# # eventsite2 <- data.frame(x.pos = c(349.025122303922, 377.228981106487, 333.704507645739, 323.606829802845),
# #                          y.pos = c(4556.83678703992, 4551.26565443695, 4527.24014508661, 4538.73060608025))
#
#
# studybnd <- data.frame(x.pos = c(303.036095033825, 303.036095033825, 323.175382381994, 323.528703212664, 345.434594714182, 346.84787803686, 368.753769538378, 368.753769538378, 394.546190177262, 394.192869346592, 415, 415, 349.674444682218, 349.674444682218),
#                        y.pos = c(4577.64270697051, 4532.06431981412, 4532.77096147546, 4518.99144907935, 4518.28480741801, 4496.73223674716, 4496.02559508582, 4490.37246179511, 4490.72578262578, 4494.61231176314, 4494.61231176314, 4557.85674045301, 4558.21006128368, 4577.28938613984))
#
# preddata <- expand.grid(x.pos = seq(min(study_fort$x), max(study_fort$x), by=1), y.pos = seq(min(study_fort$y), max(study_fort$y), by=1))
# preddata$Effort <- 1
#
require(splancs)
# preddata <- preddata[which(inout(preddata[,1:2], studybnd) == TRUE),]
# g2k <- makeDists(cbind(preddata$x.pos, preddata$y.pos), bestmod$splineParams[[1]]$knotgrid, knotmat = FALSE)$dataDist
#
# preddata$preds<-predict.gamMRSea(object=bestmod, newdata=preddata, g2k = g2k)
#
# boots<-do.bootstrap.cress.robust(bestmod, preddata, g2k=g2k, B=500)
# cis<-makeBootCIs(boots)
# preddata$lower95<-cis[,1]
# preddata$upper95<-cis[,2]
#
# preddata$sd <- apply(boots, 1, sd)
# preddata$cv <- preddata$sd/preddata$preds
#
# #require(ggplot2)
require(MRSeaPower)
ggplot(preddata, aes(x.pos, y.pos)) +
geom_tile(aes(x=x.pos, y=y.pos, fill=preds, height=1, width=1)) +
scale_fill_gradientn(colours=mypalette, space = "Lab", na.value = "grey50", guide = "colourbar", name='Estimated Density') + theme_bw() +
geom_point(data=filter(dat_summer, allanim>0), aes(x=x.pos, y=y.pos, size=log(allanim)), shape=1) +
geom_path(data=study_fort, aes(x=x, y=y, group=group),  colour='black') +
geom_path(data=lease_fort, aes(x=x, y=y, group=group, colour=Lease)) +
ggtitle('Estimated Whale Distribution') + xlab('Easting') + ylab('Northing') +
coord_equal() +
geom_polygon(data=leasebuf, aes(x=x, y=y),colour='red', fill='NA')+
scale_size_continuous(name='Log(Count)')
#
# ggplot(preddata, aes(x.pos, y.pos)) +
#   geom_tile(aes(x=x.pos, y=y.pos, fill=cv, height=1, width=1)) +
#   scale_fill_gradientn(colours=mypalette, space = "Lab
load(file='powertest_initialmodel.RObj')
eventsite = leasebuf
names(eventsite) <- c('x.pos', 'y.pos')
ggplot(preddata, aes(x.pos, y.pos)) +
geom_tile(aes(x=x.pos, y=y.pos, fill=preds, height=1, width=1)) +
scale_fill_gradientn(colours=mypalette, space = "Lab", na.value = "grey50", guide = "colourbar", name='Estimated Density') + theme_bw() +
geom_point(data=filter(dat_summer, allanim>0), aes(x=x.pos, y=y.pos, size=log(allanim)), shape=1) +
geom_path(data=study_fort, aes(x=x, y=y, group=group),  colour='black') +
geom_path(data=lease_fort, aes(x=x, y=y, group=group, colour=Lease)) +
ggtitle('Estimated Whale Distribution') + xlab('Easting') + ylab('Northing') +
coord_equal() +
geom_polygon(data=leasebuf, aes(x=x, y=y),colour='red', fill='NA')+
scale_size_continuous(name='Log(Count)')
head(dat_summer)
table(dat_summer$year)
table(dat_summer$Date)
#############
# Generate new data for post impact.  Here a 50% decline in the footprint with a re-distribution elsewhere
nsim=250
truebeta<-.05 #95% decline
dat_summer$block.num = as.numeric(as.factor(dat_summer$block))
changedata<-genChangeData(truebeta*100, model=bestmod, data=dat_summer, panels="block.num",
eventsite.bnd=eventsite)
changedata$redistid<-paste(changedata$eventphase, changedata$noneventcells)
t<-group_by(changedata, redistid)%>%
summarise(sum=sum(truth), mean=mean(truth), n=n())
t
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~
rdf1<-make.raster(ncell.y = 60,
xyzdata =changedata[changedata$eventphase==0,c('x.pos', 'y.pos', 'truth')],
z.name = 'Mean.count')
rdf2<-make.raster(ncell.y = 60,
xyzdata = changedata[changedata$eventphase==1,c('x.pos', 'y.pos', 'truth')],
z.name = 'Mean.count')
rdf<-rbind(data.frame(rdf1,evph=0) , data.frame(rdf2, evph=1))
pct.change<-((rdf$Mean.count[rdf$evph==1] - rdf$Mean.count[rdf$evph==0])/
rdf$Mean.count[rdf$evph==0])*100
ggplot( ) + geom_raster( data = rdf1 , aes( x , y , fill = pct.change ) ) +
scale_fill_gradientn(colours=mypalette,
values = c(0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.8,1, 10),
space = "Lab", na.value = "grey50",
guide = "colourbar") +
theme_bw() + coord_equal()
# generate noisy data from new truth surfaces
simdat.imp<-generateNoise(nsim, changedata$truth, family='poisson',
d=summary(bestmod)$dispersion)
#
par(mfrow=c(1,2))
quilt.plot(changedata$x.pos[changedata$eventphase==0], changedata$y.pos[changedata$eventphase==0], simdat.imp[changedata$eventphase==0,1], nrow=50, ncol=50)
polymap(eventsite, add=T)
quilt.plot(changedata$x.pos[changedata$eventphase==1], changedata$y.pos[changedata$eventphase==1],simdat.imp[changedata$eventphase==1,1], nrow=50, ncol=50)
polymap(eventsite, add=T)
dim(table(dat_summer$Date))
exp(-(2*0.2)**2)
exp(-((2*0.2)**2))
(4/2) * (4/5)
4^2/(2*5)
552.82/715
662.82/715
1450*662.82
1450*0.927021
passwords <- function(nl = 8, npw = 1, help = FALSE) {
if (help) return("gives npw passwords with nl characters each")
if (nl < 4) nl <- 4
spch <- c("!", "\"", "#", "$", "%", "&", "'", "(", ")", "*", "+", ",", "-", ".", "/", ":", ";", "<", "=", ">", "?", "@", "[", "]", "^", "_", "{", "}", "~")
for(i in 1:npw) {
pw <- c(sample(letters, 1), sample(LETTERS, 1), sample(0:9, 1), sample(spch, 1))
pw <- c(pw, sample(c(letters, LETTERS, 0:9, spch), nl-4, replace = TRUE))
cat(sample(pw), "\n", sep = "")
}
}
set.seed(123)
passwords(help = TRUE)
## [1] "gives npw passwords with nl characters each"
passwords(8)
passwords(8)
passwords(8)
aR
?spatstat::quadscheme
require(spatstat)
?quadscheme
Q <- quadscheme(simdat)
Q
Q$data
Q$dummy
Q$w
data(simdat)
head(simdat)
dim(simdat)
plot(simdat)
plot(simdat$x)
length(simdat$x)
Q <- quadscheme(simdat, nd=50)
plot(Q)
?sp::over
10/5
2*100
28*12
321/52
6*40
321/5
321/40
321/30
321/20
321/25
321/22
321/23
321/22
321/21
library(MRSea)
library(MRSea)
usethis::usepkgdown()
usethis::use_pkgdown()
pkgdown::build_site()
install.packages("knitcitations")
detach("package:base", unload = TRUE)
library(base, lib.loc = "C:/Program Files/R/R-4.2.1/library")
pkgdown::build_site()
install.packages("sandwich")
pkgdown::build_site()
usethis::use_pkgdown_github_pages()
usethis::use_pkgdown_github_pages()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
usethis::use_pkgdown_github_pages()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
1. Load the distance sampling corrected Nysted data from the package.
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, comment='#>',
message=FALSE, eval=FALSE,
collapse=TRUE, dev='png')
require(MRSea)
require(splines)
require(ggplot2)
require(dplyr)
load(file='MRSeainteracWorkspace.RData')
data("nysted.analysisdata")
mydata<-nysted.analysisdata # renamed just to be less typing!
mydata$blockid <- paste(mydata$transect.id, mydata$season, mydata$impact,sep = "")
nk=150 # number of knots per interaction level
myknots<-NULL
for(i in 1:length(unique(mydata$impact))){
faclevel<-unique(mydata$impact)[i]
tempkg<-getKnotgrid(coordData = cbind(mydata$x.pos[mydata$impact==faclevel],
mydata$y.pos[mydata$impact==faclevel]),
numKnots = nk, plot = FALSE)
myknots<-rbind(myknots, data.frame(tempkg, impact =paste(faclevel)))
}
kg<-myknots[,1:2]
require(dplyr)
dists<-makeDists(datacoords = mydata[,c('x.pos', 'y.pos')], knotcoords = kg, knotmat = TRUE)
d2k = dists$dataDist
k2k = dists$knotDist
n.level<-length(unique(myknots[,3]))
nk.in.level<-data.frame(myknots %>%
mutate(id = row_number()) %>%
group_by(impact) %>%
summarise(beg=first(id), end=last(id)))
k2k_temp<-matrix(Inf, nrow = nrow(k2k), ncol = ncol(k2k))
for(i in 1:n.level){
kid<-nk.in.level[i,'beg']:nk.in.level[i,'end']
k2k_temp[kid,kid]<-k2k[kid, kid]
}
k2k<-k2k_temp
n.level<-length(unique(myknots[,3]))
nk.in.level<-data.frame(myknots %>% mutate(id = row_number()) %>%
group_by(impact) %>%
summarise(beg=first(id), end=last(id)))
ncoords.in.level <- data.frame(mydata %>%
mutate(id = row_number()) %>%
group_by(impact) %>% summarise(beg=first(id), end=last(id)))
d2k_temp<-matrix(Inf, nrow = nrow(d2k), ncol = ncol(d2k))
for(i in 1:n.level){
kid<-nk.in.level[i,'beg']:nk.in.level[i,'end']
did<-ncoords.in.level[i,'beg']:ncoords.in.level[i,'end']
d2k_temp[did,kid]<-d2k[did, kid]
}
d2k<-d2k_temp
initialModel <- glm(response ~ as.factor(season) + as.factor(impact)
+ offset(log(area)), family = "quasipoisson",
data = mydata)
# make parameter set for running salsa2d
salsa2dlist<-list(fitnessMeasure = "QAIC",
knotgrid = myknots,
startKnots=10,
minKnots=4,
maxKnots=12)
salsa2dOutput<-runSALSA2D(model = initialModel,
salsa2dlist = salsa2dlist,
d2k=d2k,k2k=k2k)
mymodel<-salsa2dOutput$bestModel
chosenknots <- myknots[mymodel$splineParams[[1]]$knotPos,]
count(chosenknots, impact)
#startingknots <- myknots[startknotlocs,]
imp.labs <- c("Pre-Construction", "Post-Construction")
names(imp.labs) <- c("0", "1")
# quick look to see what was chosen
ggplot(myknots) +
geom_point(aes(x=X1, y=X2)) +
geom_point(aes(x=X1, y=X2, size=2), data=chosenknots, alpha=4/5,
show.legend = FALSE, shape=5) +
theme_bw() + xlab('Easting (Km)') + ylab('Northing (Km)') +
coord_equal() +
facet_wrap(~impact, ncol=1, labeller = labeller(impact=imp.labs))
mymodel$splineParams[[1]]$knotPos
set.seed(1)
cv.gamMRSea(mydata, mymodel, K=10)$delta[1]
data("nysted.predictdata")
datacoords<-nysted.predictdata[,c('x.pos', 'y.pos', 'impact')]
dists<-makeDists(datacoords = datacoords[,1:2], knotcoords = kg, knotmat = FALSE)
g2k = dists$dataDist
n.level<-length(unique(myknots[,3]))
nk.in.level<-data.frame(myknots %>%
mutate(id = row_number()) %>%
group_by(impact) %>%
summarise(beg=first(id), end=last(id)))
ncoords.in.level <- data.frame(datacoords %>%
mutate(id = row_number()) %>%
group_by(impact) %>%
summarise(beg=first(id), end=last(id)))
g2k_temp<-matrix(Inf, nrow = nrow(g2k), ncol = ncol(g2k))
for(i in 1:n.level){
kid<-nk.in.level[i,'beg']:nk.in.level[i,'end']
gid<-ncoords.in.level[i,'beg']:ncoords.in.level[i,'end']
g2k_temp[gid,kid]<-g2k[gid, kid]
}
g2k<-g2k_temp
# make predictions on response scale
nysted.predictdata$preds<-predict.gamMRSea(newdata = nysted.predictdata,
g2k =g2k,
object = mymodel)
ggplot() +
geom_tile(aes(x=x.pos, y=y.pos, fill=preds), height=0.5, width=0.5,
data=filter(nysted.predictdata, season==1)) +
coord_equal()+
scale_fill_distiller(palette = "Spectral",name="Estimated Count") +
theme_bw() +
xlab('Easting (Km)') + ylab('Northing (Km)') +
#geom_polygon(data=nysted.coast, aes(x, y), fill='grey') +
facet_wrap(~impact, ncol=1, labeller = labeller(impact = imp.labs))
ggplot() +
geom_tile(aes(x=x.pos, y=y.pos, fill=truth.re), height=0.5, width=0.5,
data=filter(nysted.predictdata, season==1)) +
coord_equal()+
scale_fill_distiller(palette = "Spectral",name="Estimated Count") +
theme_bw() +
xlab('Easting (Km)') + ylab('Northing (Km)') +
#geom_polygon(data=nysted.coast, aes(x, y), fill='grey') +
facet_wrap(~impact, ncol=1, labeller = labeller(impact = imp.labs))
startknotlocs<-c(
as.numeric(rownames(getKnotgrid(filter(myknots, impact == 0)[,1:2],
numKnots = 5, plot = FALSE))),
as.numeric(rownames(getKnotgrid(filter(myknots, impact == 1)[,1:2],
numKnots = 5, plot = FALSE))) + 150)
salsa2dlist <- list(fitnessMeasure = 'QAIC',
knotgrid = myknots,
startKnots = length(startknotlocs), ##
minKnots = 4,
maxKnots = 12,
gap = 0)
salsa2doutput_stkn<-runSALSA2D(model = initialModel,
salsa2dlist = salsa2dlist,
d2k= d2k, k2k = k2k,
initialise=FALSE,  ##
initialKnPos = startknotlocs, ##
suppress.printout = TRUE)
mymodel_sk<-salsa2doutput_stkn$bestModel
chosenknots_sk <- myknots[mymodel_sk$splineParams[[1]]$knotPos,]
startingknots <- myknots[startknotlocs,]
count(chosenknots_sk, impact)
# quick look to see what was chosen
ggplot(myknots) +
geom_point(aes(x=X1, y=X2)) +
geom_point(aes(x=X1, y=X2, size=2),data=chosenknots_sk, alpha=4/5,
show.legend = FALSE, shape=5, colour = 'firebrick') +
geom_point(aes(x=X1, y=X2, size=2), shape = 7, data=startingknots,
colour = 'darkgrey', show.legend = FALSE) +
theme_bw() + xlab('Easting (Km)') + ylab('Northing (Km)') +
coord_equal() +
facet_wrap(~impact, ncol=1, labeller = labeller(impact=imp.labs))
set.seed(1)
cv.gamMRSea(mydata, mymodel_sk, K=10)$delta[1]
# make predictions on response scale
nysted.predictdata$preds_sk<-predict.gamMRSea(newdata = nysted.predictdata,
g2k =g2k,
object = mymodel_sk)
ggplot() +
geom_tile(aes(x=x.pos, y=y.pos, fill=preds_sk), height=0.5, width=0.5,
data=filter(nysted.predictdata, season==1)) +
coord_equal()+
scale_fill_distiller(palette = "Spectral",name="Estimated Count") +
theme_bw() +
xlab('Easting (Km)') + ylab('Northing (Km)') +
#geom_polygon(data=nysted.coast, aes(x, y), fill='grey') +
facet_wrap(~impact, ncol=1, labeller = labeller(impact = imp.labs))
save.image(file='MRSeainteracWorkspace.RData', compress="bzip2")
ls(dir())
dir()
pkgdown::build_site()
