---
title: "Integration test for MRSea 2d salsa with other variables, with 1d smooth, with panels and interactions"
author: "LAS Scott-Hayward, C Fell"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


-------

```{r echo=FALSE, message=FALSE, warning=FALSE}
# devtools::install_github("lindesaysh/MRSea")
devtools::load_all("C:/Users/kryzi/OneDrive - University of St Andrews/PhD/Code/MRsea")
# require(MRSea)
require(tidyverse)
require(patchwork)
require(knitr)
require(MuMIn)
knitr::opts_chunk$set(fig=TRUE, warning=FALSE, message=FALSE, eval=TRUE, comment = '')
```

## Introduction
This is the eigth in a series of tests that can be used to check changes to the MRSea package do not break previously working elements. They replicate the case study in the vignette but broken down into chunks. This eigth one checks the 2D salsa functions with other variables, with a 1d smooth, with panels and with interactions.

```{r message=FALSE, warning=FALSE}
count.data <- read.csv("1.count.data.csv")
data <- count.data
data$response <- round(data$NHAT)
data$blockid <- paste(data$transect.id, data$season, data$impact,sep = "")
attach(data)
```

## Set up

Set a prediction grid.  

```{r, echo=FALSE}
data("nysted.predictdata")  # contains predict.data
# This is a spatial grid for making predictions.  All covariates in 
# final model must be in this data frame and the naming must be the 
# same as for the data
predictData <- nysted.predictdata

# Not including impact or season in the model so included data for only one season, season = 1 has highest count
predictData <- predictData[predictData$season==1,]

```

Set up the initial model with factor covariates and offset term
```{r message=FALSE}
initialModel <- glm(response ~ 1
  + offset(log(area)), family = "quasipoisson", data = data)

```


## Selection of flexibility for 2D smooth term

Create a grid of knots that will be used as possible knot locations.

```{r knotgrid, message=FALSE, fig=TRUE, fig.align='center', fig.width=9, fig.height=6, cache=TRUE}

knotgrid <- read.csv("4.knotgrid.csv")

```


```{r knot_comp, echo=FALSE, results='asis'}

cat("Sum of knotgrid:", sum(knotgrid), "this should be 2018630. \n\n")

```


```{r, echo=FALSE}
# make distance matrices for datatoknots and knottoknots
distMats <- makeDists(cbind(data$x.pos, data$y.pos), knotgrid)

# ~~~~~~~~~~~~~~~~~~~~~~~

```



```{r dist_comp, echo=FALSE, results='asis'}

cat("Sum of datadist:", sum(distMats$dataDist[1,]), "this should be 8224.849. \n\n")
cat("Sum of knotdist:", sum(distMats$knotDist), "this should be 1775357. \n\n")

```


Set Salsa2D parameters


```{r}

# make parameter set for running salsa2d
salsa2dlist<-list(
  fitnessMeasure = 'cv.gamMRSea', 
  knotgrid = knotgrid, 
  startKnots=5, 
  minKnots=4, 
  maxKnots=12, 
  gap=0,
  interactionTerm="as.factor(impact)",
  cv.opts=list(cv.gamMRSea.seed=1, K=10)
)
```



Run SALSA2D to find the appropriate number and location of knots for the 2D smooth term of `x.pos` and `y.pos`.

```{r message=FALSE, warning=FALSE, results='hide'}

set.seed(1234)
start_time <- Sys.time()
salsa2dOutput<-runSALSA2D(initialModel, salsa2dlist, d2k=distMats$dataDist, 
k2k=distMats$knotDist, suppress.printout=TRUE)
total_time <- Sys.time() - start_time

```


## Predictions compared to original

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=5}

predictdistMats <- makeDists(cbind(predictData$x.pos, predictData$y.pos), knotgrid)

preds_out <- predict(object=salsa2dOutput$bestModel, newdata=predictData, type='response', g2k=predictdistMats$dataDist)

pred_resp_zero <- ggplot() + stat_summary_2d(data=predictData[predictData$impact==0,], aes(x.pos, y.pos, z=preds_out[predictData$impact==0]), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 3.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New predictions - Impact=0") + theme(text=element_text(size=6))

knot_pos <- salsa2dOutput$splineParams[[1]]$knotPos
knot_loc <- knotgrid[knot_pos,]
colnames(knot_loc) <- c("xx", "yy")
rad_pos <- salsa2dOutput$splineParams[[1]]$radiusIndices
knot_loc$rad <- salsa2dOutput$splineParams[[1]]$radii[rad_pos]

for (rr in 1:nrow(knot_loc)) {
  pred_resp_zero <- pred_resp_zero + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

pred_resp_one <- ggplot() + stat_summary_2d(data=predictData[predictData$impact==1,], aes(x.pos, y.pos, z=preds_out[predictData$impact==1,]), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 3.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New predictions - Impact=1") + theme(text=element_text(size=6))

knot_pos <- salsa2dOutput$splineParams[[1]]$knotPos
knot_loc <- knotgrid[knot_pos,]
colnames(knot_loc) <- c("xx", "yy")
rad_pos <- salsa2dOutput$splineParams[[1]]$radiusIndices
knot_loc$rad <- salsa2dOutput$splineParams[[1]]$radii[rad_pos]

for (rr in 1:nrow(knot_loc)) {
  pred_resp_one <- pred_resp_one + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

predict_read_in <- read.csv("8.predict.data.csv")

resp_read_zero <- ggplot() + stat_summary_2d(data=predict_read_in[predictData$impact==0,], aes(x.pos, y.pos, z=ResponsePredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 3.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved predictions - Impact=0") + theme(text=element_text(size=6))

knot_loc_read <- read.csv("8.knot.loc.csv")

for (rr in 1:nrow(knot_loc)) {
  resp_read_zero <- resp_read_zero + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

resp_read_one <- ggplot() + stat_summary_2d(data=predict_read_in[predictData$impact==1,], aes(x.pos, y.pos, z=ResponsePredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Animal Counts", limit=c(0, 3.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved predictions - Impact=1") + theme(text=element_text(size=6))   

for (rr in 1:nrow(knot_loc)) {
  resp_read_one <- resp_read_one + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

(pred_resp_zero + resp_read_zero) / (pred_resp_one + resp_read_one) + plot_layout(guides = 'collect')

```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7.5, fig.height=5}

preds_out_link <- predict(object=salsa2dOutput$bestModel, newdata=predictData, type='link', g2k=predictdistMats$dataDist)

pred_link_zero <- ggplot() + stat_summary_2d(data=predictData[predictData$impact==0,], aes(x.pos, y.pos, z=preds_out_link[predictData$impact==0,]), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-11.5, 2.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New Predictions - Impact=0") + theme(text=element_text(size=6))

for (rr in 1:nrow(knot_loc)) {
  pred_link_zero <- pred_link_zero + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

pred_link_one <- ggplot() + stat_summary_2d(data=predictData[predictData$impact==1,], aes(x.pos, y.pos, z=preds_out_link[predictData$impact==1,]), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-11.5, 2.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("New Predictions - Impact=1") + theme(text=element_text(size=6))

for (rr in 1:nrow(knot_loc)) {
  pred_link_one <- pred_link_one + annotate("path", x=knot_loc$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

link_read_zero <- ggplot() + stat_summary_2d(data=predict_read_in[predict_read_in$impact==0,], aes(x.pos, y.pos, z=LinkPredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-11.5, 2.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved Preds - Impact=0") + theme(text=element_text(size=6))

for (rr in 1:nrow(knot_loc)) {
  link_read_zero <- link_read_zero + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

link_read_one <- ggplot() + stat_summary_2d(data=predict_read_in[predict_read_in$impact==1,], aes(x.pos, y.pos, z=LinkPredictions), fun=max, binwidth=c(0.5,0.5)) + theme_bw() + scale_fill_distiller(palette = "Spectral", name="Nhat on link scale", limit=c(-11.5, 2.8)) + coord_fixed(ratio = 1) + xlab("X coordinate") + ylab("Y coordinate") + ggtitle("Saved Preds - Impact=1") + theme(text=element_text(size=6))

for (rr in 1:nrow(knot_loc)) {
  link_read_one <- link_read_one + annotate("path", x=knot_loc_read$xx[rr] + 0.5 * cos(seq(0,2*pi,length.out=100)), y=knot_loc_read$yy[rr] + 0.5 * sin(seq(0,2*pi,length.out=100)))
}

(pred_link_zero | link_read_zero) / (pred_link_one | link_read_one) + plot_layout(guides = 'collect')

```




```{r pred_compare, echo=FALSE, results='asis'}

cat("Sum of all predictions on response scale:", sum(preds_out), "this should be 4305.88. \n\n")

cat("Sum of all predictions on link scale:", sum(preds_out_link), "this should be -11217.34. \n\n")

cat("Time for training:", round(total_time, 1), "Original time: 9.4. \n\n")

salsa2dlog <- readLines('salsa2d.log')
n_fits <- 0
for (ii in 1:length(salsa2dlog)){
  row_in <- salsa2dlog[ii]
  row_in <- as.character(row_in)
  if (grepl('fit thinplate 2D', row_in, fixed = TRUE)) {
    n_fits <- n_fits + 1
  }
}

cat("Number of model fits:", n_fits, "Original model fits: 325")

```


```{r, echo=FALSE}
sum_results <- summary(salsa2dOutput$bestModel)
kable(sum_results$coefficients, digits=3, caption="New coefficients")

```


```{r, echo=FALSE}
sum_results_read_in <- read.csv("8.sum.results.csv")
kable(sum_results_read_in, digits=3, caption="Saved coefficients")

```



```{r sum_compare, echo=FALSE, results='asis'}

cat("Sum of all estimates:", sum(sum_results$coefficients[,1]), "this should be 37.82466. \n\n")

cat("Sum of all robust SE:", sum(sum_results$coefficients[,3]), "this should be 20.26282. \n\n")

cat("Standard errors are equal to robust standard errors:", sum(sum_results$coefficients[,2])==sum(sum_results$coefficients[,3]), "\n\n")

cat("Dispersion:", sum_results$dispersion, "this should be 11.60884. \n\n")

```



```{r mean_sum_sq, echo=FALSE, results='asis'}

mean_sum_sq <- sum((predictData$truth.re - preds_out)^2)/nrow(predictData)

cat("Mean square error:", mean_sum_sq, "this should be 0.5942347. \n\n")

mean_sum_sq_data <- sum((data$response - predict.gamMRSea(newdata=data, object=salsa2dOutput$bestModel))^2)/nrow(data)

cat("Residual sum square error to data:", mean_sum_sq_data, "this should be 6.066823. \n\n")

data_compare <- data[,c('x.pos', 'y.pos')]
data_compare <- distinct(data_compare)
pred_data_compare <- predictData[,c('x.pos', 'y.pos')]

rows_seen <- do.call(paste, pred_data_compare) %in% do.call(paste, data_compare)

mean_sum_sq_seen <- sum((predictData$truth.re[rows_seen] - preds_out[rows_seen])^2)/nrow(predictData[rows_seen,])

cat("Mean square error to truth seen:", mean_sum_sq_seen, "this should be 0.6202788. \n\n")

mean_sum_sq_unseen <- sum((predictData$truth.re[!rows_seen] - preds_out[!rows_seen])^2)/nrow(predictData[!rows_seen,])

cat("Mean square error to truth unseen:", mean_sum_sq_unseen, "this should be 0.5858558. \n\n")

```







